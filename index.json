[{"content":"Introduction Bots are an increasing threat to websites, whether through fake sign ups, brute force login attempts, content scraping, or resource abuse. If you are running applications on Coolify, an open source platform as a service alternative, you need a simple and efficient way to protect them without unnecessary complexity.\nThis is where Anubis comes in. In this guide, you will learn:\nWhat Anubis is and why it is useful How it helps stop bots before they reach your application A real world example of deploying Anubis with WordPress on Coolify What is Anubis and How Does It Stop Bots? Anubis is an open source challenge proxy that protects your web applications from automated bots and abusive traffic. It works as a reverse proxy that requires clients to solve a computational proof of work challenge before granting access. This mechanism dramatically reduces malicious traffic without impacting legitimate users.\nKey features:\nActs as a reverse proxy between the Coolify proxy and your application Uses proof of work challenges to block or slow down bots Lightweight and easy to integrate with containerized environments such as Coolify Why Anubis is the Best Bot Protection for Coolify Bots can cause serious harm:\nAttempt brute force logins on your WordPress site Flood your forms with spam submissions Scrape your content or overload your server with junk traffic Exploit your site for AI scraping, an aggressive trend as companies race to collect as much data as possible for training models. This consumes bandwidth, impacts SEO, and steals your valuable content Anubis protects you by:\nChallenging every connection with a computational proof of work Filtering out malicious traffic before it reaches your application Optionally serving a robots.txt file to discourage crawlers from sensitive pages ‚úî Stops automated abuse\n‚úî Lightweight and resource friendly\n‚úî Works seamlessly with Docker and Coolify\nThe Correct Way to Deploy Anubis on Coolify A common mistake is deploying Anubis as a standalone application. This is not the correct approach.\nInstead:\nDeploy one Anubis instance per application stack For example, to protect WordPress, add Anubis into the same Docker Compose stack as your WordPress service This ensures that traffic flows correctly and that Anubis can proxy requests to your application.\nWordPress and Anubis Example Using Docker Compose Here is an example of how you can deploy WordPress with Anubis inside a Coolify stack:\nservices: anubis: image: ghcr.io/techarohq/anubis:latest expose: - \u0026#34;8923\u0026#34; environment: - SERVICE_FQDN_ANUWORDPRESS_8923 - BIND=:8923 - DIFFICULTY=5 - SERVE_ROBOTS_TXT=true - TARGET=http://wordpress wordpress: image: \u0026#39;wordpress:latest\u0026#39; volumes: - \u0026#39;wordpress-files:/var/www/html\u0026#39; environment: - WORDPRESS_DB_HOST=mariadb - WORDPRESS_DB_USER=$SERVICE_USER_WORDPRESS - WORDPRESS_DB_PASSWORD=$SERVICE_PASSWORD_WORDPRESS - WORDPRESS_DB_NAME=wordpress depends_on: - mariadb healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;curl\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;http://127.0.0.1\u0026#34;] interval: 2s timeout: 10s retries: 10 mariadb: image: \u0026#39;mariadb:11\u0026#39; volumes: - \u0026#39;mariadb-data:/var/lib/mysql\u0026#39; environment: - MYSQL_ROOT_PASSWORD=$SERVICE_PASSWORD_ROOT - MYSQL_DATABASE=wordpress - MYSQL_USER=$SERVICE_USER_WORDPRESS - MYSQL_PASSWORD=$SERVICE_PASSWORD_WORDPRESS healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;healthcheck.sh\u0026#34;, \u0026#34;--connect\u0026#34;, \u0026#34;--innodb_initialized\u0026#34;] interval: 5s timeout: 20s retries: 10 volumes: wordpress-files: mariadb-data: How This Works Anubis acts as a reverse proxy between the Coolify proxy and WordPress TARGET=http://wordpress tells Anubis where to forward traffic after the proof of work challenge is solved DIFFICULTY=5 controls the complexity of the challenge (increase for more security or decrease for better user experience) SERVE_ROBOTS_TXT=true serves a robots.txt file, which is useful for apps you do not want indexed. For public WordPress sites, disable this option Accessing WordPress Through Anubis Before deployment:\nConfigure your domain on the Anubis service, not WordPress Example: https://app.debian.local:8923 Traffic flow:\nTraefik ‚Üí Anubis ‚Üí WordPress\nWhen you visit your domain, you will first see the Anubis challenge, then your WordPress site.\nImportant: HTTPS is mandatory for production. In testing environments, you may ignore TLS warnings, but in production, always use a proper TLS certificate, such as those provided by Let‚Äôs Encrypt through Coolify.\nImportant Notes Use HTTPS in production; Anubis requires it Tune the DIFFICULTY variable for the right balance between security and usability Read the full documentation for all available environment variables:\nAnubis Installation Guide Multiple Deployments: Shared Private Key Configuration If you plan to deploy Anubis across multiple projects, you need to ensure that all Anubis instances can validate the same authentication cookies. Without this, users would need to solve proof of work challenges repeatedly or an infinite looping may occur.\nGenerate a Shared Private Key To enable cookie sharing across multiple Anubis deployments, generate a shared private key:\nopenssl rand -hex 32 This command generates a 64-character hexadecimal string that you\u0026rsquo;ll use as your shared private key.\nUpdated Docker Compose Configuration Add the ED25519_PRIVATE_KEY_HEX environment variable to your Anubis service:\nservices: anubis: image: ghcr.io/techarohq/anubis:latest expose: - \u0026#34;8923\u0026#34; environment: - SERVICE_FQDN_ANUWORDPRESS_8923 - BIND=:8923 - DIFFICULTY=5 - SERVE_ROBOTS_TXT=true - TARGET=http://wordpress - ED25519_PRIVATE_KEY_HEX=your-generated-hex-key-here Why This Matters Without shared key: Each Anubis instance generates its own private key User experience: Users get challenged repeatedly or experience infinite looping between instances With shared key: All instances can validate the same authentication cookies Result: Users solve the challenge once and can access any project seamlessly Coolify Configuration Best Practices In Coolify, it\u0026rsquo;s recommended to configure ED25519_PRIVATE_KEY_HEX as a shared environment variable rather than setting it individually for each service:\nTeam Level Configuration:\nSet the environment variable at the team level if multiple teams need to share the same domain All projects within the team will inherit this variable automatically Project Level Configuration:\nSet the environment variable at the project level if you group multiple services by domain All services within the project will use the same key Why Domain Grouping Matters:\nAll Anubis instances protecting the same domain must use the same private key This ensures seamless user experience across all services under that domain Example: app1.yourdomain.com, app2.yourdomain.com, and api.yourdomain.com should all share the same key Security Considerations Store securely: Treat this key like a password - store it in Coolify\u0026rsquo;s environment secrets Rotate periodically: Consider rotating the key periodically for enhanced security Keep private: Never commit this key to version control or share it publicly Domain-specific keys: Consider using different keys for different domains for additional security isolation This configuration is essential for production deployments with multiple replicas or load balancing.\nConclusion Anubis provides an easy yet powerful way to protect your Coolify deployed applications from bots and automated attacks. By adding it to your stack, you create an effective security layer without complex tools or application rewrites.\nStart with the example above and adapt it for your use case. Your WordPress site and your server resources will thank you.\nFAQ How does Anubis stop bots?\nBy requiring clients to solve a proof of work challenge, which makes automated attacks costly and inefficient.\nIs Anubis suitable for WordPress?\nYes, it works well as a reverse proxy in front of WordPress or any web application running on Coolify.\nDoes Anubis protect against AI scraping?\nYes, since it forces scrapers to solve proof of work challenges, which increases their resource usage and discourages bulk data collection.\n","permalink":"https://blog.laurencejones.dev/posts/anubis-coolify/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eBots are an increasing threat to websites, whether through fake sign ups, brute force login attempts, content scraping, or resource abuse. If you are running applications on \u003ca href=\"https://coolify.io\"\u003eCoolify\u003c/a\u003e, an open source platform as a service alternative, you need a simple and efficient way to protect them without unnecessary complexity.\u003c/p\u003e\n\u003cp\u003eThis is where \u003cstrong\u003eAnubis\u003c/strong\u003e comes in. In this guide, you will learn:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat Anubis is and why it is useful\u003c/li\u003e\n\u003cli\u003eHow it helps stop bots before they reach your application\u003c/li\u003e\n\u003cli\u003eA real world example of deploying Anubis with WordPress on Coolify\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"what-is-anubis-and-how-does-it-stop-bots\"\u003eWhat is Anubis and How Does It Stop Bots?\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://anubis.techaro.lol\"\u003eAnubis\u003c/a\u003e is an open source challenge proxy that protects your web applications from automated bots and abusive traffic. It works as a reverse proxy that requires clients to solve a computational proof of work challenge before granting access. This mechanism dramatically reduces malicious traffic without impacting legitimate users.\u003c/p\u003e","title":"Stop Bots on Coolify: Deploy Anubis for WordPress and Beyond"},{"content":"Nginx Rate Limit Introduction Nginx is a powerful web server that can be used to serve static content, load balance, and act as a reverse proxy. It is also capable of rate limiting requests to prevent abuse and protect your server from being overwhelmed.\nI seen various guides on how to set up rate limiting in Nginx, but I wanted to write my own since I had a specific use case in mind and I couldn\u0026rsquo;t find an example anywhere.\nI wanted to limit the number of requests to all my subdomains, but I also wanted to allow a single subdomain to bypass the rate limit.\nThis is useful when you host certain services that may require more requests than others, such as a web applications that hosts static files.\nBasic Rate Limiting Example To set up rate limiting in Nginx, you will need to add a new limit_req_zone directive to your http block. This directive will define a new rate limiting zone that will be used to track the number of requests to your server.\nPersonally I created a new file in /etc/nginx/conf.d/ called base-rate-limit.conf and added the following:\nlimit_req_zone $binary_remote_addr zone=rate_limit:10m rate=10r/s; This will create a new rate limiting zone called rate_limit that will track the number of requests to your server. The 10m parameter specifies the size of the zone, and the 10r/s parameter specifies the rate at which requests will be limited.\nNext, you will need to add a new limit_req directive to under the original limit_req_zone block. This directive will use the zone we defined earlier to limit the number of requests to your server.\nlimit_req_zone $binary_remote_addr zone=rate_limit:10m rate=10r/s; limit_req zone=rate_limit burst=20 nodelay; This will limit the number of requests to your server to 10 requests per second, with a burst of 20 requests. The nodelay parameter will prevent requests from being delayed if the rate limit is exceeded.\nChanging the default status code If you are like me and the default status code of 503 is not what you want, you can change it by adding the limit_req_status under the limit_req directive.\nlimit_req_zone $binary_remote_addr zone=rate_limit:10m rate=10r/s; limit_req zone=rate_limit burst=20 nodelay; limit_req_status 429; HTTP 429 is the status code for \u0026ldquo;Too Many Requests\u0026rdquo; and is more appropriate for rate limiting.\nBypass Rate Limiting for a Subdomain After evaluating my subdomains, I discovered that one was subjected to rate limiting, which was not my intention.\nReading through the Nginx documentation, I found that if you pass an empty string to limit_req_zone it will not create a new zone. However, I still want to track requests for some domains? How can I do this?\nThe easiest solution I found was creating 2 map functions the first would return integer value based on the $server_name variable and the second would use the integer value to return either an empty string or $binary_remote_addr.\nmap $server_name $limit { default 1; subdomain1 0; } map $limit $limit_key { 0 \u0026#34;\u0026#34;; 1 $binary_remote_addr; } limit_req_zone $limit_key zone=rate_limit:10m rate=10r/s; limit_req zone=rate_limit burst=20 nodelay; limit_req_status 429; But how do I know what the value of $server_name is? When you define a subdomain in your Nginx configuration, you can use the server_name directive to specify the domain that you want to serve.\nBypass Rate Limiting for a Domain If you want to bypass rate limiting for a whole domain, you can still use the map functions we created earlier. However, you can provide a modifier to the map function to allow you to match a domain and all its subdomains.\nmap $server_name $limit { hostnames; default 1; subdomain1 0; *.example.com 0; } map $limit $limit_key { 0 \u0026#34;\u0026#34;; 1 $binary_remote_addr; } limit_req_zone $limit_key zone=rate_limit:10m rate=10r/s; limit_req zone=rate_limit burst=20 nodelay; limit_req_status 429; As you can see above we use the hostnames; modifier to allow the strings used within the map function to be treated as hostnames. This allows us to use wildcards to match a domain and all its subdomains.\nHowever, the value returned from the map function are based on this heirarchy from the Nginx documentation:\n1. string value without a mask 2. longest string value with a prefix mask, e.g. ‚Äú*.example.com‚Äù 3. longest string value with a suffix mask, e.g. ‚Äúmail.*‚Äù 4. first matching regular expression (in order of appearance in a configuration file) 5. default value Conclusion Rate limiting is a powerful tool that can be used to protect your server from being overwhelmed by abusive requests. By using the limit_req_zone and limit_req directives, you can limit the number of requests to your server and prevent abuse.\nHaving the ability to bypass rate limiting for specific subdomains or domains is also useful, as it allows you to host services that may require more requests than others.\nI hope this guide has been helpful, and I encourage you to experiment with rate limiting in Nginx to see how it can be used to protect your server.\n","permalink":"https://blog.laurencejones.dev/posts/nginx-rate-limit/","summary":"\u003ch1 id=\"nginx-rate-limit\"\u003eNginx Rate Limit\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eNginx is a powerful web server that can be used to serve static content, load balance, and act as a reverse proxy. It is also capable of rate limiting requests to prevent abuse and protect your server from being overwhelmed.\u003c/p\u003e\n\u003cp\u003eI seen various guides on how to set up rate limiting in Nginx, but I wanted to write my own since I had a specific use case in mind and I couldn\u0026rsquo;t find an example anywhere.\u003c/p\u003e","title":"Nginx Rate Limit"},{"content":" What happened? Backstory I was setting up a new subdomain on my VPS, I thought I had everything correctly configured but the new subdomain was being routed to another application. After an hour of troubleshooting I made the decisions to reconfigure the whole server using nginxconfig.io as a baseline. Within 15 minutes of entering all the information, downloading and extracting to my server I had everything ready to go.\nThe attack I requested certificates from Lets Encrypt and had malicious requests sent to my services that were mitigated by Crowdsec.\nBreakdown of what happened üî• Certificate Transparency üìù Publicly trusted CA (Certificate Authorities) have adopted a internet security standard that provides a system of public logs that inform everybody about what certifcate have been issued and what are revoked. I highly encourage you to go to the Wiki and read the history section to understand why this was so important to implement.\nYou can go to crt.sh type in your domain to get a list of certificates that have been issued. Depending on how you generate certificates for your subdomains you may be leaking information to an attacker. For example if you issue per subdomain you will have a entry per domain instead of *.domain.tld.\nThe bad bots ü§ñ Bots must be monitoring newly issued certificates for the ability to automate attacks to new domains. Like I said earlier I set up a complete new subdomain which was not indexed by any search engines, so how could bots find this within seconds of issuance? These bots had a set pattern of attack trying these resources:\n/ /config.json /.DS_Store /ecp/Current/exporttool/microsoft.exchange.ediscovery.exporttool.application /.env /.git/config /info.php /login.action /s/3138382e3131342e39362e33/_/;/META-INF/maven/com.atlassian.jira/jira-webapp-dist/pom.properties /s/3138382e3131342e39372e33/_/;/META-INF/maven/com.atlassian.jira/jira-webapp-dist/pom.properties /server-status /telescope/requests Interesting these paths are a mixture of CVE\u0026rsquo;s and general information exposure through misconfiguration. Most likely the CVE\u0026rsquo;s they are testing for Outlook CVE-2021-28481 and Atlassian CVE-2021-26086.\nThe \u0026ldquo;good\u0026rdquo; bots üòá These bots include Censys and Google, Yes the term good bots is used lightly but at least they did not try to request CVE resources. However, Censys bot IP was already marked on the community blocklist due to the fact Censys tries to \u0026ldquo;detect\u0026rdquo; what services an IP is running. As you can see from the below picture the scanning behind this IP is very aggresive: Chart and information provided via Crowdsec Cloud Console please consider about joining the crowd!\nWhat is Crowdsec ü¶ô CrowdSec is an open-source and collaborative IPS (Intrusion Prevention System) cybersecurity stack. It leverages local behavior analysis to create a global IP reputation network. taken from website\nI have been using Crowdsec for about 7 months on my primary VPS server. Ever since installing the IDS and IPS components I have felt more consious about what attacks are happening and more importantly how it is preventing these attacks.\nI use multiple bouncers (IPS component), however, cloudflare bouncer took the brunt of the attacks that happened following issuing the certficates.\nSince these IP\u0026rsquo;s were within the community blocklist, they were already banned before even getting to my server. All this for free! Please checkout out Crowdsec and if you wish to join the community join the Discord Server.\n","permalink":"https://blog.laurencejones.dev/posts/ct-bots/","summary":"\u003chr\u003e\n\u003ch1 id=\"what-happened\"\u003eWhat happened?\u003c/h1\u003e\n\u003ch2 id=\"backstory\"\u003eBackstory\u003c/h2\u003e\n\u003cp\u003eI was setting up a new subdomain on my VPS, I thought I had everything correctly configured but the new subdomain was being routed to another application. After an hour of troubleshooting I made the decisions to reconfigure the whole server using \u003ca href=\"https://nginxconfig.io/\"\u003enginxconfig.io\u003c/a\u003e as a baseline. Within 15 minutes of entering all the information, downloading and extracting to my server I had everything ready to go.\u003c/p\u003e\n\u003ch2 id=\"the-attack\"\u003eThe attack\u003c/h2\u003e\n\u003cp\u003eI requested certificates from \u003ca href=\"https://letsencrypt.org/\"\u003eLets Encrypt\u003c/a\u003e and had malicious requests sent to my services that were mitigated by Crowdsec.\u003c/p\u003e","title":"Certificate Transparency Bots"},{"content":" What is a dork? A dork is a filter that can be applied to searches to narrow down the results to what you are looking for. This is often used to find potential documents / hidden pages that were accidentally exposed to the internet. This can be used in recon stage since it does not interact with a target / organisation directly.\nThere are many dork operators here is a list and what effect they have on the results.\nDork Description Example site Filter results down to specfic site Site:laurencejones.dev Or Site:blog.laurencejones.dev filetype Searches for a particular filetype. filetype:\u0026quot;pdf\u0026quot; cache Shows the version of the web page that Google has in its cache. cache:blog.laurencejones.dev intext Searches for the keywords all at once or one at a time. intext:\u0026quot;keyword\u0026quot; inurl Searches for a URL matching one of the keywords. inurl:\u0026quot;keyword\u0026quot; intitle Searches for keywords in title all or one. intitle:\u0026quot;keyword\u0026quot; allintext Searches for all keywords given. allintext:\u0026quot;keyword\u0026quot; allinurl Searches for a URL matching all keywords. allinurl:\u0026quot;keyword\u0026quot; allintitle Searches for all keywords in title. allintitle:\u0026quot;keyword\u0026quot; link Searches for external links to pages. link:\u0026quot;keyword\u0026quot; numrange Used to locate specific numbers. numrange:300-325 before/after Used to search within a particular date range. filetype:pdf \u0026amp; (before:2020-01-01 after:2021-01-01) allinanchor (and also inanchor) This shows sites which have the keyterms in links pointing to them, in order of the most links. inanchor:dog allinpostauthor (and also inpostauthor) Exclusive to blog search, this one picks out blog posts that are written by specific individuals. allinpostauthor:\u0026quot;keyword\u0026quot; related List web pages that are ‚Äúsimilar‚Äù to a specified page. related:blog.laurencejones.dev Additional search operators:\nOR operator\nintitle:admin | intitle:finance AND operator\nintitle:admin \u0026amp; inurl:ftp Example searches Website Interesting website files:\nsite:\u0026lt;target\u0026gt; (ext:pdf | ext:txt | ext:log | ext:doc | ext:docx | ext:pptx | ext:xlsx | ext:xlsm | ext:xlsb | ext:xltx | ext:xltm | ext:xlt |ext:xls | ext:xml | ext:xlam | ext:xla | ext:xlw | ext:xlr | ext:docm | ext:dot | ext:dotm | ext:dotx | ext:htm | ext:mht | ext:mhtml | ext:odt | ext:rtf | ext:wps | ext:xps | ext:ini) Index of:\nsite:\u0026lt;target\u0026gt; intitle:\u0026#34;index of /*\u0026#34; //Optional \u0026gt; (inurl:ftp | inurl:login | inurl:smb | inurl: admin) Username intitle:\u0026lt;username\u0026gt; | inurl:\u0026lt;username\u0026gt; | intext:\u0026lt;username\u0026gt; Extras List of dorking tools: Github Google Hacking Database: GHDB Cheatsheet: Gist ","permalink":"https://blog.laurencejones.dev/posts/google-dorks/","summary":"\u003chr\u003e\n\u003ch2 id=\"what-is-a-dork\"\u003eWhat is a dork?\u003c/h2\u003e\n\u003cp\u003eA dork is a filter that can be applied to searches to narrow down the results to what you are looking for. This is often used to find potential documents / hidden pages that were accidentally exposed to the internet. This can be used in recon stage since it does not interact with a target / organisation directly.\u003c/p\u003e\n\u003cp\u003eThere are many dork operators here is a list and what effect they have on the results.\u003c/p\u003e","title":"Google Dorks"},{"content":" What is NGINX? NGINX is open source software for web serving, reverse proxying, caching, load balancing, media streaming, and more. It started out as a web server designed for maximum performance and stability. In addition to its HTTP server capabilities, NGINX can also function as a proxy server for email (IMAP, POP3, and SMTP) and a reverse proxy and load balancer for HTTP, TCP, and UDP servers. source\nWhat is a WAF? A WAF or web application firewall helps protect web applications by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web applications from attacks such as cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection, among others. A WAF is a protocol layer 7 defense (in the OSI model), and is not designed to defend against all types of attacks. This method of attack mitigation is usually part of a suite of tools which together create a holistic defense against a range of attack vectors. source We now have a general understanding of what Nginx is and what a WAF can do here are the two main products that can be used:\nNginx App Protect Nginx App Protect is the main commercial WAF provided by F5 as an addon to Nginx Plus. Using this product can reduce the complexity and time to go live compared to \u0026ldquo;rolling your own\u0026rdquo;.\nNginx Mod Security 3.0 Nginx Mod Security 3.0 is an open-source dynamic module that can be used with the paid and open-source version of Nginx. However, there is a catch with the open-source version you must compile the module from source which can be a barrier for entry. Now we know which products we can use in conjunction with Nginx. We must now define a set of rules to control which request should be dropped from the application, it is best practice to use a base rule set that has been thoroughly tested.\nOWASP CRS OWASP Core Rule Set is an open-source rule set provided by the OWASP Foundation to define a set of general detections to protect web applications with the focus to have minimum false positives. In the next post, we will work on setting up a lab environment to get hands-on experience and how we can use docker to streamline the process.\n","permalink":"https://blog.laurencejones.dev/posts/nginx-waf-overview/","summary":"\u003chr\u003e\n\u003ch2 id=\"what-is-nginx\"\u003eWhat is NGINX?\u003c/h2\u003e\n\u003cp\u003eNGINX is open source software for web serving, reverse proxying, caching, load balancing, media streaming, and more. It started out as a web server designed for maximum performance and stability. In addition to its HTTP server capabilities, NGINX can also function as a proxy server for email (IMAP, POP3, and SMTP) and a reverse proxy and load balancer for HTTP, TCP, and UDP servers. source\u003c/p\u003e\n\u003ch2 id=\"what-is-a-waf\"\u003eWhat is a WAF?\u003c/h2\u003e\n\u003cp\u003eA WAF or web application firewall helps protect web applications by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web applications from attacks such as cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection, among others. A WAF is a protocol layer 7 defense (in the OSI model), and is not designed to defend against all types of attacks. This method of attack mitigation is usually part of a suite of tools which together create a holistic defense against a range of attack vectors. source\nWe now have a general understanding of what Nginx is and what a WAF can do here are the two main products that can be used:\u003c/p\u003e","title":"Nginx Waf Overview"}]